{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccb989bb-5034-4136-8e2e-3cf528e74680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "# nltk.download('all')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e33a2c06-8882-4368-a9cc-efe08d176573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemoveStopWords(texto):\n",
    "    stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "    palavras = [i for i in texto.split() if not i in stopwords]\n",
    "    return (\" \".join(palavras))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.str.lower() \n",
    "    text = text.str.replace(r\"\\#\",\"\") \n",
    "    text = text.str.replace(r\"http\\S+\",\"\")  \n",
    "    text = text.str.replace(r\"@\",\"\")\n",
    "    text = text.str.replace(r\"[^a-zA-Z#]\", \" \")\n",
    "    text = text.str.replace(\"\\s{2,}\", \"\")\n",
    "    return text\n",
    "\n",
    "def preprocess(text, stopwords=stopwords.words('english')):\n",
    "    \"\"\"Conditional preprocessing on our text unique to our task.\"\"\"\n",
    "    # Lower\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove stopwords\n",
    "    pattern = re.compile(r'\\b(' + r'|'.join(stopwords) + r')\\b\\s*')\n",
    "    text = pattern.sub('', text)\n",
    "\n",
    "    # Remove words in paranthesis\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "\n",
    "    # Spacing and filters\n",
    "    text = re.sub(r\"([-;;.,!?<=>])\", r\" \\1 \", text)\n",
    "    text = re.sub('[^A-Za-z0-9]+', ' ', text) # remove non alphanumeric chars\n",
    "    text = re.sub(' +', ' ', text)  # remove multiple spaces\n",
    "    text = text.strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "def tokenize_tweet(x):\n",
    "    tokeniser = TreebankWordTokenizer()\n",
    "    tokens = tokeniser.tokenize(x)\n",
    "    return tokens\n",
    "\n",
    "def load_datasets():\n",
    "    train_path = os.path.join('..','data','raw','train.csv')\n",
    "    test_path = os.path.join('..','data','raw','test.csv')\n",
    "    train = pd.read_csv(train_path)\n",
    "    test = pd.read_csv(test_path)\n",
    "    train = train.drop(['keyword', 'location', 'id'], axis=1)\n",
    "    test = test.drop(['keyword', 'location', 'id'], axis=1)\n",
    "        \n",
    "    train['text_clean'] = [RemoveStopWords(i) for i in train['text']]\n",
    "    train['text_clean'] = clean_text(train['text_clean'])\n",
    "    train['text_token'] = [tokenize_tweet(i) for i in train['text_clean']]\n",
    "    train = train[['text','text_clean','text_token','target']]\n",
    "    \n",
    "    test['text_clean'] = [RemoveStopWords(i) for i in test['text']]\n",
    "    test['text_clean'] = clean_text(test['text_clean'])\n",
    "    test['text_token'] = [tokenize_tweet(i) for i in test['text_clean']]\n",
    "    test = test[['text','text_clean','text_token']]\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f2f5ddf-f876-42b7-9d0c-c1aa7dcbfa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = load_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "860ec51c-edca-424a-ba6d-64d18a9be626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_token</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>our deeds reason earthquake may allah forgive us</td>\n",
       "      <td>[our, deeds, reason, earthquake, may, allah, f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>forest fire near la ronge saskcanada</td>\n",
       "      <td>[forest, fire, near, la, ronge, saskcanada]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>all residents askedshelter placenotified offic...</td>\n",
       "      <td>[all, residents, askedshelter, placenotified, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>people receive wildfires evacuation orders cal...</td>\n",
       "      <td>[people, receive, wildfires, evacuation, order...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>just got sent photo ruby alaska smoke wildfire...</td>\n",
       "      <td>[just, got, sent, photo, ruby, alaska, smoke, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Our Deeds are the Reason of this #earthquake M...   \n",
       "1             Forest fire near La Ronge Sask. Canada   \n",
       "2  All residents asked to 'shelter in place' are ...   \n",
       "3  13,000 people receive #wildfires evacuation or...   \n",
       "4  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0   our deeds reason earthquake may allah forgive us   \n",
       "1               forest fire near la ronge saskcanada   \n",
       "2  all residents askedshelter placenotified offic...   \n",
       "3  people receive wildfires evacuation orders cal...   \n",
       "4  just got sent photo ruby alaska smoke wildfire...   \n",
       "\n",
       "                                          text_token  target  \n",
       "0  [our, deeds, reason, earthquake, may, allah, f...       1  \n",
       "1        [forest, fire, near, la, ronge, saskcanada]       1  \n",
       "2  [all, residents, askedshelter, placenotified, ...       1  \n",
       "3  [people, receive, wildfires, evacuation, order...       1  \n",
       "4  [just, got, sent, photo, ruby, alaska, smoke, ...       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "383bb1c4-a988-4cbd-a655-06fbd70f910b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>just happened terrible car crash</td>\n",
       "      <td>[just, happened, terrible, car, crash]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>heard earthquake different citiesstay safe eve...</td>\n",
       "      <td>[heard, earthquake, different, citiesstay, saf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>forest fire spot pondgeese fleeing across stre...</td>\n",
       "      <td>[forest, fire, spot, pondgeese, fleeing, acros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>apocalypse lightingspokane wildfires</td>\n",
       "      <td>[apocalypse, lightingspokane, wildfires]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>typhoon soudelor killschina taiwan</td>\n",
       "      <td>[typhoon, soudelor, killschina, taiwan]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                 Just happened a terrible car crash   \n",
       "1  Heard about #earthquake is different cities, s...   \n",
       "2  there is a forest fire at spot pond, geese are...   \n",
       "3           Apocalypse lighting. #Spokane #wildfires   \n",
       "4      Typhoon Soudelor kills 28 in China and Taiwan   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0                   just happened terrible car crash   \n",
       "1  heard earthquake different citiesstay safe eve...   \n",
       "2  forest fire spot pondgeese fleeing across stre...   \n",
       "3               apocalypse lightingspokane wildfires   \n",
       "4                 typhoon soudelor killschina taiwan   \n",
       "\n",
       "                                          text_token  \n",
       "0             [just, happened, terrible, car, crash]  \n",
       "1  [heard, earthquake, different, citiesstay, saf...  \n",
       "2  [forest, fire, spot, pondgeese, fleeing, acros...  \n",
       "3           [apocalypse, lightingspokane, wildfires]  \n",
       "4            [typhoon, soudelor, killschina, taiwan]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b02615c-9397-464f-94f9-e758e857d9e1",
   "metadata": {},
   "source": [
    "TFIDF vector transformer with svm binary classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04470069-bd17-4fb2-afe5-e2c7c7829b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "X = train.text_clean\n",
    "y = train.target\n",
    "\n",
    "td = TfidfVectorizer(max_features = train.shape[0])\n",
    "X = td.fit_transform(X).toarray()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b59866fd-837c-40ad-a662-053b8c2b11da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayman\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [42:03<00:00, 87.03s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.78</td>\n",
       "      <td>3.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.77</td>\n",
       "      <td>112.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NearestCentroid</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.77</td>\n",
       "      <td>3.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.75</td>\n",
       "      <td>237.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.75</td>\n",
       "      <td>244.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NuSVC</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.74</td>\n",
       "      <td>428.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.74</td>\n",
       "      <td>69.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.74</td>\n",
       "      <td>416.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.72</td>\n",
       "      <td>5.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.71</td>\n",
       "      <td>158.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>5.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveClassifier</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.70</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CalibratedClassifierCV</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.71</td>\n",
       "      <td>279.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.70</td>\n",
       "      <td>4.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeClassifier</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.69</td>\n",
       "      <td>4.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.68</td>\n",
       "      <td>69.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.69</td>\n",
       "      <td>71.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.67</td>\n",
       "      <td>7.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.65</td>\n",
       "      <td>26.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.59</td>\n",
       "      <td>3.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>6.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>89.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.59</td>\n",
       "      <td>208.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelSpreading</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.54</td>\n",
       "      <td>9.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelPropagation</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.54</td>\n",
       "      <td>8.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuadraticDiscriminantAnalysis</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.49</td>\n",
       "      <td>35.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.49</td>\n",
       "      <td>2.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
       "Model                                                                           \n",
       "BernoulliNB                        0.79               0.77     0.77      0.78   \n",
       "RandomForestClassifier             0.77               0.76     0.76      0.77   \n",
       "NearestCentroid                    0.77               0.75     0.75      0.77   \n",
       "ExtraTreesClassifier               0.75               0.74     0.74      0.75   \n",
       "BaggingClassifier                  0.75               0.74     0.74      0.75   \n",
       "NuSVC                              0.74               0.73     0.73      0.74   \n",
       "XGBClassifier                      0.75               0.72     0.72      0.74   \n",
       "SVC                                0.75               0.72     0.72      0.74   \n",
       "LGBMClassifier                     0.73               0.71     0.71      0.72   \n",
       "DecisionTreeClassifier             0.71               0.70     0.70      0.71   \n",
       "LogisticRegression                 0.70               0.70     0.70      0.70   \n",
       "PassiveAggressiveClassifier        0.70               0.69     0.69      0.70   \n",
       "CalibratedClassifierCV             0.71               0.69     0.69      0.71   \n",
       "Perceptron                         0.70               0.69     0.69      0.70   \n",
       "ExtraTreeClassifier                0.70               0.68     0.68      0.69   \n",
       "LinearSVC                          0.68               0.67     0.67      0.68   \n",
       "AdaBoostClassifier                 0.71               0.67     0.67      0.69   \n",
       "SGDClassifier                      0.69               0.66     0.66      0.67   \n",
       "RidgeClassifierCV                  0.64               0.64     0.64      0.65   \n",
       "GaussianNB                         0.59               0.61     0.61      0.59   \n",
       "RidgeClassifier                    0.61               0.61     0.61      0.61   \n",
       "LinearDiscriminantAnalysis         0.58               0.58     0.58      0.58   \n",
       "KNeighborsClassifier               0.61               0.57     0.57      0.59   \n",
       "LabelSpreading                     0.63               0.56     0.56      0.54   \n",
       "LabelPropagation                   0.63               0.56     0.56      0.54   \n",
       "QuadraticDiscriminantAnalysis      0.51               0.53     0.53      0.49   \n",
       "DummyClassifier                    0.49               0.48     0.48      0.49   \n",
       "\n",
       "                               Time Taken  \n",
       "Model                                      \n",
       "BernoulliNB                          3.27  \n",
       "RandomForestClassifier             112.62  \n",
       "NearestCentroid                      3.01  \n",
       "ExtraTreesClassifier               237.44  \n",
       "BaggingClassifier                  244.96  \n",
       "NuSVC                              428.78  \n",
       "XGBClassifier                       69.44  \n",
       "SVC                                416.98  \n",
       "LGBMClassifier                       5.26  \n",
       "DecisionTreeClassifier             158.51  \n",
       "LogisticRegression                   5.53  \n",
       "PassiveAggressiveClassifier          5.64  \n",
       "CalibratedClassifierCV             279.77  \n",
       "Perceptron                           4.01  \n",
       "ExtraTreeClassifier                  4.59  \n",
       "LinearSVC                           69.54  \n",
       "AdaBoostClassifier                  71.20  \n",
       "SGDClassifier                        7.10  \n",
       "RidgeClassifierCV                   26.21  \n",
       "GaussianNB                           3.91  \n",
       "RidgeClassifier                      6.63  \n",
       "LinearDiscriminantAnalysis          89.06  \n",
       "KNeighborsClassifier               208.53  \n",
       "LabelSpreading                       9.16  \n",
       "LabelPropagation                     8.85  \n",
       "QuadraticDiscriminantAnalysis       35.94  \n",
       "DummyClassifier                      2.36  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lazypredict.Supervised import LazyClassifier\n",
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2a17483-925a-404b-a446-0da28e64342e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import BernoulliNB\n",
    "# BernoulliNB??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80a01e7a-842c-478b-a0e1-8d0a5caef851",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, make_scorer\n",
    "\n",
    "def min_recall_precision(est, X, y_true, sample_weight=None):\n",
    "    y_pred = est.predict(X)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    return min(recall, precision)\n",
    "\n",
    "X = train.text_clean\n",
    "y = train.target\n",
    "\n",
    "td = TfidfVectorizer(max_features = train.shape[0])\n",
    "X = td.fit_transform(X).toarray()\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "clf_gaus_standard = Pipeline([\n",
    "        (\"scale\", scaler),\n",
    "        (\"model\", BernoulliNB())\n",
    "    ])\n",
    "\n",
    "clf_gaus_pca = Pipeline([\n",
    "        (\"scale\", scaler),\n",
    "        ('reduce_dim', PCA()),\n",
    "        (\"model\", BernoulliNB())\n",
    "    ])\n",
    "\n",
    "clf_gaus_lda = Pipeline([\n",
    "        (\"scale\", scaler),\n",
    "        ('reduce_dim', LDA()),\n",
    "        (\"model\", BernoulliNB())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a3516ec-e9dc-479b-8ae5-1b12acb5a12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_model__alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_precision</th>\n",
       "      <th>split1_test_precision</th>\n",
       "      <th>split2_test_precision</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>...</th>\n",
       "      <th>split1_test_min_both</th>\n",
       "      <th>split2_test_min_both</th>\n",
       "      <th>mean_test_min_both</th>\n",
       "      <th>std_test_min_both</th>\n",
       "      <th>rank_test_min_both</th>\n",
       "      <th>split0_train_min_both</th>\n",
       "      <th>split1_train_min_both</th>\n",
       "      <th>split2_train_min_both</th>\n",
       "      <th>mean_train_min_both</th>\n",
       "      <th>std_train_min_both</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.74</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>{'model__alpha': 0.1}</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>...</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.68</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.20</td>\n",
       "      <td>{'model__alpha': 0.2}</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>...</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.76</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.30</td>\n",
       "      <td>{'model__alpha': 0.30000000000000004}</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.67</td>\n",
       "      <td>...</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.66</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.40</td>\n",
       "      <td>{'model__alpha': 0.4}</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.68</td>\n",
       "      <td>...</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.03</td>\n",
       "      <td>4</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.69</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.50</td>\n",
       "      <td>{'model__alpha': 0.5}</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>...</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.77</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.60</td>\n",
       "      <td>{'model__alpha': 0.6}</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>...</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.89</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.70</td>\n",
       "      <td>{'model__alpha': 0.7000000000000001}</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>...</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.06</td>\n",
       "      <td>7</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.99</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.80</td>\n",
       "      <td>{'model__alpha': 0.8}</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>...</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.72</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.90</td>\n",
       "      <td>{'model__alpha': 0.9}</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.72</td>\n",
       "      <td>...</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.06</td>\n",
       "      <td>9</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.22</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.00</td>\n",
       "      <td>{'model__alpha': 1.0}</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.73</td>\n",
       "      <td>...</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.06</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0           2.74          0.07             1.10            0.00   \n",
       "1           2.68          0.04             1.14            0.06   \n",
       "2           2.76          0.15             1.15            0.05   \n",
       "3           2.66          0.03             1.03            0.02   \n",
       "4           2.69          0.05             1.04            0.04   \n",
       "5           2.77          0.01             1.15            0.05   \n",
       "6           2.89          0.08             1.21            0.07   \n",
       "7           2.99          0.03             1.12            0.03   \n",
       "8           2.72          0.05             1.03            0.02   \n",
       "9           2.22          0.38             0.85            0.17   \n",
       "\n",
       "  param_model__alpha                                 params  \\\n",
       "0               0.10                  {'model__alpha': 0.1}   \n",
       "1               0.20                  {'model__alpha': 0.2}   \n",
       "2               0.30  {'model__alpha': 0.30000000000000004}   \n",
       "3               0.40                  {'model__alpha': 0.4}   \n",
       "4               0.50                  {'model__alpha': 0.5}   \n",
       "5               0.60                  {'model__alpha': 0.6}   \n",
       "6               0.70   {'model__alpha': 0.7000000000000001}   \n",
       "7               0.80                  {'model__alpha': 0.8}   \n",
       "8               0.90                  {'model__alpha': 0.9}   \n",
       "9               1.00                  {'model__alpha': 1.0}   \n",
       "\n",
       "   split0_test_precision  split1_test_precision  split2_test_precision  \\\n",
       "0                   0.67                   0.62                   0.64   \n",
       "1                   0.69                   0.62                   0.65   \n",
       "2                   0.70                   0.63                   0.66   \n",
       "3                   0.72                   0.64                   0.67   \n",
       "4                   0.73                   0.65                   0.68   \n",
       "5                   0.74                   0.65                   0.69   \n",
       "6                   0.74                   0.66                   0.70   \n",
       "7                   0.76                   0.67                   0.71   \n",
       "8                   0.76                   0.68                   0.71   \n",
       "9                   0.78                   0.68                   0.72   \n",
       "\n",
       "   mean_test_precision  ...  split1_test_min_both  split2_test_min_both  \\\n",
       "0                 0.64  ...                  0.61                  0.64   \n",
       "1                 0.65  ...                  0.61                  0.65   \n",
       "2                 0.67  ...                  0.61                  0.66   \n",
       "3                 0.68  ...                  0.60                  0.67   \n",
       "4                 0.68  ...                  0.59                  0.68   \n",
       "5                 0.69  ...                  0.57                  0.69   \n",
       "6                 0.70  ...                  0.56                  0.70   \n",
       "7                 0.71  ...                  0.56                  0.68   \n",
       "8                 0.72  ...                  0.55                  0.68   \n",
       "9                 0.73  ...                  0.54                  0.67   \n",
       "\n",
       "   mean_test_min_both  std_test_min_both  rank_test_min_both  \\\n",
       "0                0.63               0.01                   3   \n",
       "1                0.63               0.02                   2   \n",
       "2                0.63               0.02                   1   \n",
       "3                0.63               0.03                   4   \n",
       "4                0.62               0.04                   5   \n",
       "5                0.62               0.05                   6   \n",
       "6                0.61               0.06                   7   \n",
       "7                0.60               0.06                   8   \n",
       "8                0.59               0.06                   9   \n",
       "9                0.58               0.06                  10   \n",
       "\n",
       "   split0_train_min_both  split1_train_min_both  split2_train_min_both  \\\n",
       "0                   0.84                   0.83                   0.85   \n",
       "1                   0.83                   0.81                   0.83   \n",
       "2                   0.82                   0.81                   0.82   \n",
       "3                   0.81                   0.80                   0.82   \n",
       "4                   0.80                   0.79                   0.80   \n",
       "5                   0.79                   0.78                   0.80   \n",
       "6                   0.78                   0.78                   0.79   \n",
       "7                   0.77                   0.77                   0.78   \n",
       "8                   0.76                   0.75                   0.77   \n",
       "9                   0.75                   0.75                   0.76   \n",
       "\n",
       "   mean_train_min_both  std_train_min_both  \n",
       "0                 0.84                0.01  \n",
       "1                 0.83                0.01  \n",
       "2                 0.82                0.01  \n",
       "3                 0.81                0.01  \n",
       "4                 0.80                0.01  \n",
       "5                 0.79                0.01  \n",
       "6                 0.78                0.00  \n",
       "7                 0.77                0.00  \n",
       "8                 0.76                0.01  \n",
       "9                 0.75                0.00  \n",
       "\n",
       "[10 rows x 39 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_standard = GridSearchCV(estimator=clf_gaus_standard,\n",
    "                   param_grid={\n",
    "                       'model__alpha':np.linspace(0.1,1,10),\n",
    "                   },\n",
    "                   scoring={'precision': make_scorer(precision_score), \n",
    "                             'recall': make_scorer(recall_score),\n",
    "                             'min_both': min_recall_precision},\n",
    "                    refit='min_both',\n",
    "                    return_train_score=True,\n",
    "                    cv=3,\n",
    "                    n_jobs=-1)\n",
    "mod_standard.fit(X, y);\n",
    "\n",
    "pd.DataFrame(mod_standard.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8853386-b67e-48b3-b855-23a70998c72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_model__alpha</th>\n",
       "      <th>param_reduce_dim__n_components</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_precision</th>\n",
       "      <th>split1_test_precision</th>\n",
       "      <th>split2_test_precision</th>\n",
       "      <th>...</th>\n",
       "      <th>split1_test_min_both</th>\n",
       "      <th>split2_test_min_both</th>\n",
       "      <th>mean_test_min_both</th>\n",
       "      <th>std_test_min_both</th>\n",
       "      <th>rank_test_min_both</th>\n",
       "      <th>split0_train_min_both</th>\n",
       "      <th>split1_train_min_both</th>\n",
       "      <th>split2_train_min_both</th>\n",
       "      <th>mean_train_min_both</th>\n",
       "      <th>std_train_min_both</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.82</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__alpha': 0.1, 'reduce_dim__n_component...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>982</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.74</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2</td>\n",
       "      <td>{'model__alpha': 0.1, 'reduce_dim__n_component...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.51</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.21</td>\n",
       "      <td>940</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.15</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>{'model__alpha': 0.1, 'reduce_dim__n_component...</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.11</td>\n",
       "      <td>965</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.50</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.10</td>\n",
       "      <td>4</td>\n",
       "      <td>{'model__alpha': 0.1, 'reduce_dim__n_component...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.46</td>\n",
       "      <td>...</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.07</td>\n",
       "      <td>951</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.83</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.10</td>\n",
       "      <td>5</td>\n",
       "      <td>{'model__alpha': 0.1, 'reduce_dim__n_component...</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.54</td>\n",
       "      <td>...</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.05</td>\n",
       "      <td>936</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>10.85</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.00</td>\n",
       "      <td>95</td>\n",
       "      <td>{'model__alpha': 1.0, 'reduce_dim__n_component...</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.02</td>\n",
       "      <td>51</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>10.61</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.00</td>\n",
       "      <td>96</td>\n",
       "      <td>{'model__alpha': 1.0, 'reduce_dim__n_component...</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.58</td>\n",
       "      <td>...</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.02</td>\n",
       "      <td>41</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>10.56</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.00</td>\n",
       "      <td>97</td>\n",
       "      <td>{'model__alpha': 1.0, 'reduce_dim__n_component...</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.02</td>\n",
       "      <td>6</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>12.45</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.00</td>\n",
       "      <td>98</td>\n",
       "      <td>{'model__alpha': 1.0, 'reduce_dim__n_component...</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.01</td>\n",
       "      <td>167</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>9.26</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.00</td>\n",
       "      <td>99</td>\n",
       "      <td>{'model__alpha': 1.0, 'reduce_dim__n_component...</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>72</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>990 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0             4.82          0.01             0.81            0.02   \n",
       "1             4.74          0.09             0.88            0.01   \n",
       "2             5.15          0.16             0.94            0.05   \n",
       "3             5.50          0.08             1.00            0.02   \n",
       "4             4.83          0.05             0.82            0.03   \n",
       "..             ...           ...              ...             ...   \n",
       "985          10.85          0.05             1.40            0.09   \n",
       "986          10.61          0.24             1.16            0.21   \n",
       "987          10.56          1.10             1.15            0.07   \n",
       "988          12.45          0.30             1.29            0.03   \n",
       "989           9.26          0.29             1.01            0.05   \n",
       "\n",
       "    param_model__alpha param_reduce_dim__n_components  \\\n",
       "0                 0.10                              1   \n",
       "1                 0.10                              2   \n",
       "2                 0.10                              3   \n",
       "3                 0.10                              4   \n",
       "4                 0.10                              5   \n",
       "..                 ...                            ...   \n",
       "985               1.00                             95   \n",
       "986               1.00                             96   \n",
       "987               1.00                             97   \n",
       "988               1.00                             98   \n",
       "989               1.00                             99   \n",
       "\n",
       "                                                params  split0_test_precision  \\\n",
       "0    {'model__alpha': 0.1, 'reduce_dim__n_component...                   0.00   \n",
       "1    {'model__alpha': 0.1, 'reduce_dim__n_component...                   0.00   \n",
       "2    {'model__alpha': 0.1, 'reduce_dim__n_component...                   0.51   \n",
       "3    {'model__alpha': 0.1, 'reduce_dim__n_component...                   0.50   \n",
       "4    {'model__alpha': 0.1, 'reduce_dim__n_component...                   0.52   \n",
       "..                                                 ...                    ...   \n",
       "985  {'model__alpha': 1.0, 'reduce_dim__n_component...                   0.59   \n",
       "986  {'model__alpha': 1.0, 'reduce_dim__n_component...                   0.56   \n",
       "987  {'model__alpha': 1.0, 'reduce_dim__n_component...                   0.59   \n",
       "988  {'model__alpha': 1.0, 'reduce_dim__n_component...                   0.58   \n",
       "989  {'model__alpha': 1.0, 'reduce_dim__n_component...                   0.56   \n",
       "\n",
       "     split1_test_precision  split2_test_precision  ...  split1_test_min_both  \\\n",
       "0                     0.42                   0.00  ...                  0.08   \n",
       "1                     0.50                   0.51  ...                  0.50   \n",
       "2                     0.50                   0.00  ...                  0.26   \n",
       "3                     0.56                   0.46  ...                  0.20   \n",
       "4                     0.48                   0.54  ...                  0.26   \n",
       "..                     ...                    ...  ...                   ...   \n",
       "985                   0.53                   0.56  ...                  0.53   \n",
       "986                   0.53                   0.58  ...                  0.53   \n",
       "987                   0.55                   0.56  ...                  0.55   \n",
       "988                   0.53                   0.56  ...                  0.53   \n",
       "989                   0.55                   0.56  ...                  0.55   \n",
       "\n",
       "     split2_test_min_both  mean_test_min_both  std_test_min_both  \\\n",
       "0                    0.00                0.03               0.04   \n",
       "1                    0.16                0.22               0.21   \n",
       "2                    0.00                0.13               0.11   \n",
       "3                    0.08                0.18               0.07   \n",
       "4                    0.28                0.24               0.05   \n",
       "..                    ...                 ...                ...   \n",
       "985                  0.56                0.56               0.02   \n",
       "986                  0.58                0.56               0.02   \n",
       "987                  0.56                0.57               0.02   \n",
       "988                  0.56                0.55               0.01   \n",
       "989                  0.56                0.55               0.00   \n",
       "\n",
       "     rank_test_min_both  split0_train_min_both  split1_train_min_both  \\\n",
       "0                   982                   0.00                   0.11   \n",
       "1                   940                   0.00                   0.54   \n",
       "2                   965                   0.18                   0.33   \n",
       "3                   951                   0.26                   0.27   \n",
       "4                   936                   0.21                   0.32   \n",
       "..                  ...                    ...                    ...   \n",
       "985                  51                   0.59                   0.63   \n",
       "986                  41                   0.60                   0.63   \n",
       "987                   6                   0.60                   0.64   \n",
       "988                 167                   0.59                   0.63   \n",
       "989                  72                   0.57                   0.63   \n",
       "\n",
       "     split2_train_min_both  mean_train_min_both  std_train_min_both  \n",
       "0                     0.00                 0.04                0.05  \n",
       "1                     0.18                 0.24                0.22  \n",
       "2                     0.00                 0.17                0.14  \n",
       "3                     0.10                 0.21                0.08  \n",
       "4                     0.22                 0.25                0.05  \n",
       "..                     ...                  ...                 ...  \n",
       "985                   0.58                 0.60                0.02  \n",
       "986                   0.58                 0.60                0.02  \n",
       "987                   0.59                 0.61                0.02  \n",
       "988                   0.59                 0.60                0.02  \n",
       "989                   0.59                 0.60                0.02  \n",
       "\n",
       "[990 rows x 40 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_pca = GridSearchCV(estimator=clf_gaus_pca,\n",
    "                   param_grid={\n",
    "                       'model__alpha':np.linspace(0.1,1,10),\n",
    "                       'reduce_dim__n_components':np.arange(1,100)\n",
    "                   },\n",
    "                   scoring={'precision': make_scorer(precision_score), \n",
    "                             'recall': make_scorer(recall_score),\n",
    "                             'min_both': min_recall_precision},\n",
    "                    refit='min_both',\n",
    "                    return_train_score=True,\n",
    "                    cv=3,\n",
    "                    n_jobs=-1)\n",
    "mod_pca.fit(X, y);\n",
    "\n",
    "pd.DataFrame(mod_pca.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e16f2b3-ce25-46f2-9192-9e4b6f7182f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_model__alpha</th>\n",
       "      <th>param_reduce_dim__n_components</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_precision</th>\n",
       "      <th>split1_test_precision</th>\n",
       "      <th>split2_test_precision</th>\n",
       "      <th>...</th>\n",
       "      <th>split1_test_min_both</th>\n",
       "      <th>split2_test_min_both</th>\n",
       "      <th>mean_test_min_both</th>\n",
       "      <th>std_test_min_both</th>\n",
       "      <th>rank_test_min_both</th>\n",
       "      <th>split0_train_min_both</th>\n",
       "      <th>split1_train_min_both</th>\n",
       "      <th>split2_train_min_both</th>\n",
       "      <th>mean_train_min_both</th>\n",
       "      <th>std_train_min_both</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>360.31</td>\n",
       "      <td>5.09</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__alpha': 0.1, 'reduce_dim__n_component...</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.44</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>334.96</td>\n",
       "      <td>22.21</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__alpha': 0.2, 'reduce_dim__n_component...</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.44</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>314.03</td>\n",
       "      <td>18.39</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__alpha': 0.30000000000000004, 'reduce_...</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.44</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>290.38</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__alpha': 0.4, 'reduce_dim__n_component...</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.44</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>286.49</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__alpha': 0.5, 'reduce_dim__n_component...</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.44</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>304.23</td>\n",
       "      <td>12.84</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__alpha': 0.6, 'reduce_dim__n_component...</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.44</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>311.53</td>\n",
       "      <td>9.50</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__alpha': 0.7000000000000001, 'reduce_d...</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.44</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>293.05</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__alpha': 0.8, 'reduce_dim__n_component...</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.44</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>307.39</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__alpha': 0.9, 'reduce_dim__n_component...</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.44</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>220.47</td>\n",
       "      <td>59.04</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>{'model__alpha': 1.0, 'reduce_dim__n_component...</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.44</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0         360.31          5.09             1.10            0.17   \n",
       "1         334.96         22.21             0.94            0.10   \n",
       "2         314.03         18.39             1.01            0.18   \n",
       "3         290.38          0.17             0.91            0.03   \n",
       "4         286.49          1.02             0.88            0.04   \n",
       "5         304.23         12.84             1.13            0.19   \n",
       "6         311.53          9.50             1.11            0.11   \n",
       "7         293.05          0.56             1.27            0.20   \n",
       "8         307.39          0.85             1.07            0.08   \n",
       "9         220.47         59.04             0.69            0.25   \n",
       "\n",
       "  param_model__alpha param_reduce_dim__n_components  \\\n",
       "0               0.10                              1   \n",
       "1               0.20                              1   \n",
       "2               0.30                              1   \n",
       "3               0.40                              1   \n",
       "4               0.50                              1   \n",
       "5               0.60                              1   \n",
       "6               0.70                              1   \n",
       "7               0.80                              1   \n",
       "8               0.90                              1   \n",
       "9               1.00                              1   \n",
       "\n",
       "                                              params  split0_test_precision  \\\n",
       "0  {'model__alpha': 0.1, 'reduce_dim__n_component...                   0.44   \n",
       "1  {'model__alpha': 0.2, 'reduce_dim__n_component...                   0.44   \n",
       "2  {'model__alpha': 0.30000000000000004, 'reduce_...                   0.44   \n",
       "3  {'model__alpha': 0.4, 'reduce_dim__n_component...                   0.44   \n",
       "4  {'model__alpha': 0.5, 'reduce_dim__n_component...                   0.44   \n",
       "5  {'model__alpha': 0.6, 'reduce_dim__n_component...                   0.44   \n",
       "6  {'model__alpha': 0.7000000000000001, 'reduce_d...                   0.44   \n",
       "7  {'model__alpha': 0.8, 'reduce_dim__n_component...                   0.44   \n",
       "8  {'model__alpha': 0.9, 'reduce_dim__n_component...                   0.44   \n",
       "9  {'model__alpha': 1.0, 'reduce_dim__n_component...                   0.44   \n",
       "\n",
       "   split1_test_precision  split2_test_precision  ...  split1_test_min_both  \\\n",
       "0                   0.45                   0.44  ...                  0.45   \n",
       "1                   0.45                   0.44  ...                  0.45   \n",
       "2                   0.45                   0.44  ...                  0.45   \n",
       "3                   0.45                   0.44  ...                  0.45   \n",
       "4                   0.45                   0.44  ...                  0.45   \n",
       "5                   0.45                   0.44  ...                  0.45   \n",
       "6                   0.45                   0.44  ...                  0.45   \n",
       "7                   0.45                   0.44  ...                  0.45   \n",
       "8                   0.45                   0.44  ...                  0.45   \n",
       "9                   0.45                   0.44  ...                  0.45   \n",
       "\n",
       "   split2_test_min_both  mean_test_min_both  std_test_min_both  \\\n",
       "0                  0.44                0.44               0.01   \n",
       "1                  0.44                0.44               0.01   \n",
       "2                  0.44                0.44               0.01   \n",
       "3                  0.44                0.44               0.01   \n",
       "4                  0.44                0.44               0.01   \n",
       "5                  0.44                0.44               0.01   \n",
       "6                  0.44                0.44               0.01   \n",
       "7                  0.44                0.44               0.01   \n",
       "8                  0.44                0.44               0.01   \n",
       "9                  0.44                0.44               0.01   \n",
       "\n",
       "   rank_test_min_both  split0_train_min_both  split1_train_min_both  \\\n",
       "0                   1                   0.97                   0.98   \n",
       "1                   1                   0.97                   0.98   \n",
       "2                   1                   0.97                   0.98   \n",
       "3                   1                   0.97                   0.98   \n",
       "4                   1                   0.97                   0.98   \n",
       "5                   1                   0.97                   0.98   \n",
       "6                   1                   0.97                   0.98   \n",
       "7                   1                   0.97                   0.98   \n",
       "8                   1                   0.97                   0.98   \n",
       "9                   1                   0.97                   0.98   \n",
       "\n",
       "   split2_train_min_both  mean_train_min_both  std_train_min_both  \n",
       "0                   0.98                 0.98                0.00  \n",
       "1                   0.98                 0.98                0.00  \n",
       "2                   0.98                 0.98                0.00  \n",
       "3                   0.98                 0.98                0.00  \n",
       "4                   0.98                 0.98                0.00  \n",
       "5                   0.98                 0.98                0.00  \n",
       "6                   0.98                 0.98                0.00  \n",
       "7                   0.98                 0.98                0.00  \n",
       "8                   0.98                 0.98                0.00  \n",
       "9                   0.98                 0.98                0.00  \n",
       "\n",
       "[10 rows x 40 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_lda = GridSearchCV(estimator=clf_gaus_lda,\n",
    "                   param_grid={\n",
    "                       'model__alpha':np.linspace(0.1,1,10),\n",
    "                       'reduce_dim__n_components':[1]\n",
    "                   },\n",
    "                   scoring={'precision': make_scorer(precision_score), \n",
    "                             'recall': make_scorer(recall_score),\n",
    "                             'min_both': min_recall_precision},\n",
    "                    refit='min_both',\n",
    "                    return_train_score=True,\n",
    "                    cv=3,\n",
    "                    n_jobs=-1)\n",
    "mod_lda.fit(X, y);\n",
    "\n",
    "pd.DataFrame(mod_lda.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3946c134-3a8b-46a9-a413-06109e8d3417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac430f2-16fa-484d-9944-72d2a391d7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def classifier_test(df, feature, target, classifier):\n",
    "    print(\"_\"*54)\n",
    "    print(f'Classifier: {classifier}')\n",
    "    X = df[f'{feature}']\n",
    "    y = df[f'{target}']\n",
    "\n",
    "    td = TfidfVectorizer(max_features = df.shape[0])\n",
    "    X = td.fit_transform(X).toarray()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    clf = classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    print(classification_report(y_test, pred))\n",
    "    print(\"_\"*54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fe6ede-a976-48b9-8286-0ecbba566fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_test(train, 'text_clean', 'target', GaussianNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d393fa19-1ac8-4489-8502-32a63e7e4bac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90509f3a-70d2-400f-91b3-9f50949f6d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff48554-3293-4d35-841e-255728091af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2190f32-a59d-4639-8eb2-c84c5b00219e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9bf5c1-5e4f-415f-b5c4-c60e21f26056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638fe7a3-cb27-4cff-906d-5cf04a58d605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99207ce-eb7b-4efb-a2fc-79db8fd69f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer  = TfidfVectorizer(min_df=1,use_idf= True, stop_words = 'english')\n",
    "dtm = vectorizer.fit_transform(train['text_clean'])\n",
    "\n",
    "pd.DataFrame(dtm.toarray(),index=train,columns=vectorizer.get_feature_names()).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5e3348-d7d6-4ab0-954c-0938225a1a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit LSA. Use algorithm = “randomized” for large datasets\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "lsa = TruncatedSVD(2, algorithm = 'arpack')\n",
    "dtm_lsa = lsa.fit_transform(dtm)\n",
    "dtm_lsa = Normalizer(copy=False).fit_transform(dtm_lsa)\n",
    "\n",
    "pd.DataFrame(lsa.components_,index = [\"component_1\",\"component_2\"],columns =\n",
    "vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b8a420-7ab2-4f5c-889c-e3a327d8611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(dtm_lsa, index = train, columns = [\"component_1\",\"component_2\"]).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c04597-1426-4ac2-9487-cae24b1cb43a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb385f4-76d4-49b2-9218-926b9638a879",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ebf2a2-f171-4506-a226-0986600b8576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc779ba-9916-4778-a77f-0f0f775d1f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a59bd3e-d88a-4d7f-866c-e0b4ad68aed6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabca229-4248-4c3a-b197-71f85abbddbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29764939-67c2-4cfb-9ead-7a66a86f2a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8384746f-0b63-48ff-bd78-25dd3df7df58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4691fc1f-5a1b-49b8-864a-5328198734d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dca65e-0f33-4d31-af48-1df5e2665d65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac588b8-44d4-43fe-975a-59975c1f9b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X = train.text_clean\n",
    "y = train.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "clf = text_clf = Pipeline(\n",
    "    [\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('standardscaler', StandardScaler()),\n",
    "        ('svc', SVC(gamma='auto'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "text_clf.fit(X_train, y_train)\n",
    "predicted = text_clf.predict(X_test)\n",
    "classification_report(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06be0189-7372-4259-b05f-28b291085fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize.casual import casual_tokenize\n",
    "corpus = train.text_clean.to_list()\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=casual_tokenize)\n",
    "tfidf_transformer = vectorizer.fit_transform(corpus)\n",
    "print(tfidf_transformer.shape)\n",
    "\n",
    "target = train.target.values.reshape(-1,1)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3310e036-aa64-4afc-b8f5-f11153b6c736",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "X_train = newsgroups_train.data\n",
    "X_test = newsgroups_test.data\n",
    "y_train = newsgroups_train.target\n",
    "y_test = newsgroups_test.target\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "                     ])\n",
    "text_clf.fit(X_train, y_train)\n",
    "predicted = text_clf.predict(X_test)\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f451fb-69d8-4b93-8fd5-f85d13dcf4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e86e55a-ff31-4469-bdd2-3895c1479e06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6845d040-9afa-4661-ade8-4e2c9f480062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ffbf83-160c-402c-8ab1-ea6b1329a67d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4101a841-f06d-430a-a156-4cacab5d4840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1975e5f-90df-4cd7-a873-3246eb7dfd99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
